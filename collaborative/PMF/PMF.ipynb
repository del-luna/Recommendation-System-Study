{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0356bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, find\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "parameters = {\n",
    "    'lambda_a': 1e-2,\n",
    "    'lambda_b': 1e-2,\n",
    "    'momentum': 0.9,\n",
    "    'num_features': 30,\n",
    "    'epochs': 10,\n",
    "    'lr': 3e-5,\n",
    "    'batch_size':30000\n",
    "}\n",
    "\n",
    "df = pd.read_csv('./data/netflix/netflix.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "full_rows = df['user']\n",
    "full_cols = df['movie']\n",
    "full_ratings = df['rating']\n",
    "\n",
    "full_csr = csr_matrix((full_ratings,(full_rows, full_cols)))\n",
    "\n",
    "train, valid = train_test_split(df, test_size=0.4, shuffle=True, random_state=42)\n",
    "valid, test = train_test_split(valid, test_size=0.5, shuffle=True, random_state=42)\n",
    "\n",
    "valid_rows = valid['user']\n",
    "valid_cols = valid['movie']\n",
    "valid_ratings = valid['rating']\n",
    "\n",
    "valid_csr = csr_matrix((valid_ratings, (valid_rows,valid_cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee3a39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PMF():\n",
    "    def __init__(self, full_data, valid_data, params):\n",
    "        self.R = full_data\n",
    "        self._lambda_alpha = params['lambda_a']\n",
    "        self._lambda_beta = params['lambda_b']\n",
    "        self.momentum = params['momentum']\n",
    "        self.num_features = params['num_features']\n",
    "        self.iterations = params['epochs']\n",
    "        self.lr = params['lr']\n",
    "        self.batch_size = params['batch_size']\n",
    "        self.I = copy.deepcopy(self.R).astype('uint8')\n",
    "        self.I[self.I != 0] = 1\n",
    "        self.v_rows, self.v_cols, self.v_rat = find(valid_data)\n",
    "        \n",
    "        self.U = 0.1*np.random.randn(self.R.shape[0], self.num_features)\n",
    "        self.V = 0.1*np.random.randn(self.R.shape[1], self.num_features)\n",
    "    \n",
    "\n",
    "    def loss(self, idx):\n",
    "        '''\n",
    "        The Frobenius norm is the same as the L2 norm, \n",
    "        and since the squares are added, the formula is written as follows.\n",
    "        '''\n",
    "        \n",
    "        loss = np.sum(np.multiply(self.I[idx, :], (self.R[idx, :]-np.dot(self.U[idx, :], self.V.T))**2)) + self._lambda_alpha*np.sum(np.square(self.U[idx, :])) + self.lambda_beta*np.sum(np.square(self.V))\n",
    "        return loss\n",
    "    \n",
    "    def predict(self):\n",
    "        '''\n",
    "        Validation-only function\n",
    "        '''\n",
    "        u_features = self.U.take(self.v_rows, axis=0)\n",
    "        v_features = self.V.take(self.v_cols, axis=0)\n",
    "        preds_value_array = np.sum(u_features*v_features, 1)\n",
    "        return preds_value_array\n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        train_loss_list = []\n",
    "        vali_rmse_list = []\n",
    "        last_vali_rmse = None\n",
    "\n",
    "        # monemtum\n",
    "        momuntum_u = np.zeros(self.U.shape)\n",
    "        momuntum_v = np.zeros(self.V.shape)\n",
    "        \n",
    "        for epoch in tqdm(range(self.iterations)):\n",
    "            \n",
    "            shuffled_order = np.arange(full_csr.shape[0])\n",
    "            np.random.shuffle(shuffled_order)\n",
    "            train_loss = 0\n",
    "            momuntum_v = 0\n",
    "            \n",
    "            for batch in range(int(len(shuffled_order / self.batch_size)) + 1):\n",
    "                \n",
    "                if batch == int(len(shuffled_order / self.batch_size)): #last batch\n",
    "                    test = np.arange(self.batch_size*batch, full_csr.shape[0])\n",
    "                    batch_idx = np.mod(test, shuffled_order.shape[0])\n",
    "                else:\n",
    "                    test = np.arange(self.batch_size * batch, self.batch_size * (batch+1))\n",
    "                    batch_idx = np.mod(test, shuffled_order.shape[0])\n",
    "                \n",
    "                # get gradient\n",
    "                mse = np.multiply(self.I[batch_idx,:], (self.R[batch_idx,:] - np.dot(self.U[batch_idx, :], self.V.T)))\n",
    "                \n",
    "\n",
    "                d_U = np.dot(mse, - self.V) + self._lambda_alpha*self.U[batch_idx, :]\n",
    "                d_V = np.dot(mse.T, - self.U[batch_idx, :]) + self._lambda_alpha*self.V\n",
    "                \n",
    "                #update the parameters\n",
    "                momuntum_u = (self.momuntum * momuntum_u) + self.lr * d_U\n",
    "                momuntum_v += (self.momuntum * momuntum_v) + self.lr * d_V\n",
    "    \n",
    "                \n",
    "                #training evaluation\n",
    "                #save the loss before gradient update\n",
    "                train_loss += np.sum(mse**2) + self._lambda_alpha*np.sum(np.square(self.U[idx, :])) + self.lambda_beta*np.sum(np.square(self.V))\n",
    "                self.U[batch_idx, :] = self.U[batch_idx, :] - momuntum_u\n",
    "                \n",
    "            #cumlative sum of gradient V update\n",
    "            self.V = self.V - momuntum_v \n",
    "            \n",
    "            # Average over the cumulative sum of batch loss\n",
    "            train_loss_list.append(train_loss/(int(len(shuffled_order / self.batch_size)) + 1))\n",
    "                \n",
    "                \n",
    "            '''\n",
    "            여기서는 최소한 batch단위 업데이트 끝나고 즉, U가 한바퀴는 다 돌리고 나서 수행됨.\n",
    "            '''\n",
    "            vali_preds = self.predict()\n",
    "            vali_rmse = RMSE(self.v_rats, vali_preds)\n",
    "            vali_rmse_list.append(vali_rmse)\n",
    "            \n",
    "            print('traning iteration:{: d} ,loss:{: f}, vali_rmse:{: f}'.format(it, train_loss, vali_rmse))\n",
    "\n",
    "            if last_vali_rmse and (last_vali_rmse - vali_rmse) <= 0:\n",
    "                print('convergence at iterations:{: d}'.format(it))\n",
    "                break\n",
    "            else:\n",
    "                last_vali_rmse = vali_rmse\n",
    "\n",
    "\n",
    "        return self.U, self.V, train_loss_list, vali_rmse_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7600b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PMF(full_csr, valid_csr, params=parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9e1166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]Exception ignored in: <generator object tqdm.__iter__ at 0x00000224591099E0>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\std.py\", line 1193, in __iter__\n",
      "    self.close()\n",
      "  File \"c:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\std.py\", line 1287, in close\n",
      "    fp_write('')\n",
      "  File \"c:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\std.py\", line 1284, in fp_write\n",
      "    self.fp.write(_unicode(s))\n",
      "  File \"c:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\tqdm\\utils.py\", line 142, in inner\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\iostream.py\", line 402, in write\n",
      "    self.pub_thread.schedule(lambda : self._buffer.write(string))\n",
      "  File \"c:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\ipykernel\\iostream.py\", line 203, in schedule\n",
      "    self._event_pipe.send(b'')\n",
      "  File \"c:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\zmq\\sugar\\socket.py\", line 505, in send\n",
      "    return super(Socket, self).send(data, flags=flags, copy=copy, track=track)\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 718, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 765, in zmq.backend.cython.socket.Socket.send\n",
      "  File \"zmq\\backend\\cython\\socket.pyx\", line 242, in zmq.backend.cython.socket._send_copy\n",
      "  File \"zmq\\backend\\cython\\checkrc.pxd\", line 13, in zmq.backend.cython.checkrc._check_rc\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.63 MiB for an array with shape (1130800,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-9ab0f5f430c6>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;31m# get gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[1;31m#import pdb;pdb.set_trace()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mV\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    473\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;31m# scalar value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda3\\envs\\torch\\lib\\site-packages\\scipy\\sparse\\data.py\u001b[0m in \u001b[0;36m_mul_scalar\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_mul_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.63 MiB for an array with shape (1130800,) and data type float64"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "U, V, train_loss_list, vali_rmse_list = model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a647e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
